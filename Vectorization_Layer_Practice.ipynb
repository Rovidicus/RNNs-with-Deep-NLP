{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b4a2086-9d28-4186-adbe-604cdac5c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# Then Set Random Seeds\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "# Then run the Enable Deterministic Operations Function\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0bb6658-c527-4507-bcd6-dd8238f0f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')\n",
    "pd.set_option('display.max_colwidth', 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b44eb4-e4ec-48f3-8e83-c94f12eb56dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "def classification_metrics(y_true, y_pred, label='',\n",
    "                           output_dict=False, figsize=(8,4),\n",
    "                           normalize='true', cmap='Blues',\n",
    "                           colorbar=False,values_format=\".2f\"):\n",
    "    \"\"\"Modified version of classification metrics function from Intro to Machine Learning.\n",
    "    Updates:\n",
    "    - Reversed raw counts confusion matrix cmap  (so darker==more).\n",
    "    - Added arg for normalized confusion matrix values_format\n",
    "    \"\"\"\n",
    "    # Get the classification report\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    \n",
    "    ## Print header and report\n",
    "    header = \"-\"*70\n",
    "    print(header, f\" Classification Metrics: {label}\", header, sep='\\n')\n",
    "    print(report)\n",
    "    \n",
    "    ## CONFUSION MATRICES SUBPLOTS\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=figsize)\n",
    "    \n",
    "    # Create a confusion matrix  of raw counts (left subplot)\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                                            normalize=None, \n",
    "                                            cmap='gist_gray_r',# Updated cmap\n",
    "                                            values_format=\"d\", \n",
    "                                            colorbar=colorbar,\n",
    "                                            ax = axes[0]);\n",
    "    axes[0].set_title(\"Raw Counts\")\n",
    "    \n",
    "    # Create a confusion matrix with the data with normalize argument \n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                                            normalize=normalize,\n",
    "                                            cmap=cmap, \n",
    "                                            values_format=values_format, #New arg\n",
    "                                            colorbar=colorbar,\n",
    "                                            ax = axes[1]);\n",
    "    axes[1].set_title(\"Normalized Confusion Matrix\")\n",
    "    \n",
    "    # Adjust layout and show figure\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return dictionary of classification_report\n",
    "    if output_dict==True:\n",
    "        report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "        return report_dict\n",
    "    \n",
    "    \n",
    "def evaluate_classification(model, X_train, y_train, X_test, y_test,\n",
    "                         figsize=(6,4), normalize='true', output_dict = False,\n",
    "                            cmap_train='Blues', cmap_test=\"Reds\",colorbar=False):\n",
    "  # Get predictions for training data\n",
    "  y_train_pred = model.predict(X_train)\n",
    "  # Call the helper function to obtain regression metrics for training data\n",
    "  results_train = classification_metrics(y_train, y_train_pred, #verbose = verbose,\n",
    "                                     output_dict=True, figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_train,\n",
    "                                     label='Training Data')\n",
    "  print()\n",
    "  # Get predictions for test data\n",
    "  y_test_pred = model.predict(X_test)\n",
    "  # Call the helper function to obtain regression metrics for test data\n",
    "  results_test = classification_metrics(y_test, y_test_pred, #verbose = verbose,\n",
    "                                  output_dict=True,figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_test,\n",
    "                                    label='Test Data' )\n",
    "  if output_dict == True:\n",
    "    # Store results in a dataframe if ouput_frame is True\n",
    "    results_dict = {'train':results_train,\n",
    "                    'test': results_test}\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd3fc5b-5ab4-4cd1-8bd2-19e2d4dc8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function for preprocessing texts\n",
    "def batch_preprocess_texts(\n",
    "    texts,\n",
    "    nlp=None,\n",
    "    remove_stopwords=True,\n",
    "    remove_punct=True,\n",
    "    use_lemmas=False,\n",
    "    disable=[\"ner\"],\n",
    "    batch_size=50,\n",
    "    n_process=-1,\n",
    "):\n",
    "    \"\"\"Efficiently preprocess a collection of texts using nlp.pipe()\n",
    "\n",
    "    Args:\n",
    "        texts (collection of strings): collection of texts to process (e.g. df['text'])\n",
    "        nlp (spacy pipe), optional): Spacy nlp pipe. Defaults to None; if None, it creates a default 'en_core_web_sm' pipe.\n",
    "        remove_stopwords (bool, optional): Controls stopword removal. Defaults to True.\n",
    "        remove_punct (bool, optional): Controls punctuation removal. Defaults to True.\n",
    "        use_lemmas (bool, optional): lemmatize tokens. Defaults to False.\n",
    "        disable (list of strings, optional): named pipeline elements to disable. Defaults to [\"ner\"]: Used with nlp.pipe(disable=disable)\n",
    "        batch_size (int, optional): Number of texts to process in a batch. Defaults to 50.\n",
    "        n_process (int, optional): Number of CPU processors to use. Defaults to -1 (meaning all CPU cores).\n",
    "\n",
    "    Returns:\n",
    "        list of tokens\n",
    "    \"\"\"\n",
    "    # from tqdm.notebook import tqdm\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    if nlp is None:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    processed_texts = []\n",
    "\n",
    "    for doc in tqdm(nlp.pipe(texts, disable=disable, batch_size=batch_size, n_process=n_process)):\n",
    "        tokens = []\n",
    "        for token in doc:\n",
    "            # Check if should remove stopwords and if token is stopword\n",
    "            if (remove_stopwords == True) and (token.is_stop == True):\n",
    "                # Continue the loop with the next token\n",
    "                continue\n",
    "\n",
    "            # Check if should remove stopwords and if token is stopword\n",
    "            if (remove_punct == True) and (token.is_punct == True):\n",
    "                continue\n",
    "\n",
    "            # Check if should remove stopwords and if token is stopword\n",
    "            if (remove_punct == True) and (token.is_space == True):\n",
    "                continue\n",
    "\n",
    "            \n",
    "            ## Determine final form of output list of tokens/lemmas\n",
    "            if use_lemmas:\n",
    "                tokens.append(token.lemma_.lower())\n",
    "            else:\n",
    "                tokens.append(token.text.lower())\n",
    "\n",
    "        processed_texts.append(tokens)\n",
    "    return processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33d21bdc-f2d8-44ae-9744-daa474221603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling might be a mere mistake.</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                            text  \\\n",
       "id                                                                                                                                                                                                                                                 \n",
       "id26305  This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.   \n",
       "id17569                                                                                                                                                                  It never once occurred to me that the fumbling might be a mere mistake.   \n",
       "id11008                                 In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.   \n",
       "id27763                           How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.   \n",
       "id12958                                                           Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.   \n",
       "\n",
       "        author  \n",
       "id              \n",
       "id26305    EAP  \n",
       "id17569    HPL  \n",
       "id11008    EAP  \n",
       "id27763    MWS  \n",
       "id12958    HPL  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in horror author data\n",
    "df = pd.read_csv(\"Data/spooky.csv\", index_col = \"id\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2650faf-182f-4b57-a7b0-99b83b31779a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19579 entries, id26305 to id00393\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    19579 non-null  object\n",
      " 1   author  19579 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 458.9+ KB\n",
      "Duplicate count: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking nulls and duplicates\n",
    "df.info()\n",
    "print(f'Duplicate count: {df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6847d16-1784-4f02-bc77-8a222f61d218",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9814214-c05a-408c-81aa-486172d0adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "# additional imports needed\n",
    "from nltk.probability import FreqDist\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1ff4c2e-1f0d-4882-913c-0e471a740e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'attribute_ruler', 'lemmatizer']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use spacy to make a tokens columns using appropriate components\n",
    "nlp_light = spacy.load(\"en_core_web_sm\", disable=['parser','ner'])\n",
    "# Print active components\n",
    "nlp_light.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a64af059-0f34-46f5-88b9-6452bc4cc722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19579it [01:37, 200.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[process, afforded, means, ascertaining, dimensions, dungeon, circuit, return, point, set, aware, fact, perfectly, uniform, wall]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling might be a mere mistake.</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[occurred, fumbling, mere, mistake]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[left, hand, gold, snuff, box, capered, hill, cutting, manner, fantastic, steps, took, snuff, incessantly, air, greatest, possible, self, satisfaction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[lovely, spring, looked, windsor, terrace, sixteen, fertile, counties, spread, beneath, speckled, happy, cottages, wealthier, towns, looked, years, heart, cheering, fair]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[finding, gold, superintendent, abandoned, attempts, perplexed, look, occasionally, steals, countenance, sits, thinking, desk]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                            text  \\\n",
       "id                                                                                                                                                                                                                                                 \n",
       "id26305  This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.   \n",
       "id17569                                                                                                                                                                  It never once occurred to me that the fumbling might be a mere mistake.   \n",
       "id11008                                 In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.   \n",
       "id27763                           How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.   \n",
       "id12958                                                           Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.   \n",
       "\n",
       "        author  \\\n",
       "id               \n",
       "id26305    EAP   \n",
       "id17569    HPL   \n",
       "id11008    EAP   \n",
       "id27763    MWS   \n",
       "id12958    HPL   \n",
       "\n",
       "                                                                                                                                                                             tokens  \n",
       "id                                                                                                                                                                                   \n",
       "id26305                                           [process, afforded, means, ascertaining, dimensions, dungeon, circuit, return, point, set, aware, fact, perfectly, uniform, wall]  \n",
       "id17569                                                                                                                                         [occurred, fumbling, mere, mistake]  \n",
       "id11008                     [left, hand, gold, snuff, box, capered, hill, cutting, manner, fantastic, steps, took, snuff, incessantly, air, greatest, possible, self, satisfaction]  \n",
       "id27763  [lovely, spring, looked, windsor, terrace, sixteen, fertile, counties, spread, beneath, speckled, happy, cottages, wealthier, towns, looked, years, heart, cheering, fair]  \n",
       "id12958                                              [finding, gold, superintendent, abandoned, attempts, perplexed, look, occasionally, steals, countenance, sits, thinking, desk]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using custom function to preprocess our text column into tokens\n",
    "df['tokens'] = batch_preprocess_texts(df['text'], nlp = nlp_light)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3352a0-247f-4eb6-a863-be0d1a3a2563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6955it [00:53, 328.80it/s]"
     ]
    }
   ],
   "source": [
    "# batch preprocess the text and store lemmas\n",
    "df['lemmas'] = batch_preprocess_texts(df['text'], nlp = nlp_light, use_lemmas = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b83c2e-3d8d-474b-8d8e-fc6e819d9fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join list of tokens into a string with spaces between each token\n",
    "df['tokens-joined'] = df['tokens'].map(lambda x: \" \".join(x))\n",
    "# Join list of lemmas into a string with spaces between each lemma\n",
    "df['lemmas-joined'] = df['lemmas'].map(lambda x: \" \".join(x))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8788803-cf7b-40b9-993c-d8114b2bc587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making new column to find the average word count for real and fake news articles\n",
    "df['wc'] = df['tokens'].apply(lambda x: len(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e029e81d-88ac-4f4e-892d-564699a9c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting average tokens for horror lines\n",
    "df['wc'].mean().round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335de847-9a4e-4995-9244-f63d52c93c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to change our target to integers for modeling. Changing EAP to 0, HPL to 1, MWS to 2.\n",
    "df['author'] = df['author'].replace(\"EAP\", 0).replace(\"HPL\", 1).replace(\"MWS\", 2)\n",
    "df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf3a6fc-807f-476c-88fe-b59ab9e0bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking balance of our target author columns\n",
    "y = df['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321ba8fd-7e1e-481e-a0c8-a597d3ec879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d8e7a-aa6c-4d9f-b68f-cb2191e9737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling\n",
    "sampler = RandomUnderSampler(random_state = 42)\n",
    "X_res, y_res = sampler.fit_resample(X.values.reshape(-1,1),y)\n",
    "X_res = X_res.flatten()\n",
    "# Doublechecking class imbalance\n",
    "y_res.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c56458-23f2-43fa-9236-f4343954e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Dataset object\n",
    "ds = tf.data.Dataset.from_tensor_slices((X_res, y_res))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11e3ed3-cb1a-4438-b406-f6c493b50d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling the data once\n",
    "ds = ds.shuffle(buffer_size=len(ds), reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7685e6-9b4f-4bcd-8597-6726da60a85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determing how many samples for each split\n",
    "# Calculate the number of samples for training \n",
    "split_train = 0.7\n",
    "n_train_samples =  int(len(ds) * split_train)\n",
    "print(f\"Use {n_train_samples} samples as training data\")\n",
    "# Calculate the number of samples for validation\n",
    "split_val = 0.2\n",
    "n_val_samples = int(len(ds) * split_val)\n",
    "print(f\"Use {n_val_samples} samples as validation data\")\n",
    "# Test size is remainder\n",
    "split_test = 1 - (split_train + split_val)\n",
    "print(f\"The remaining {len(ds)- (n_train_samples+n_val_samples)} samples will be used as test data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4517e49a-4e40-4b3b-ae4c-ccb3505d42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .take to slice out the number of samples for training\n",
    "train_ds = ds.take(n_train_samples)\n",
    "# Skipover the training batches\n",
    "val_ds = ds.skip(n_train_samples)\n",
    "# Take .take to slice out the correct number of samples for validation\n",
    "val_ds = val_ds.take(n_val_samples)\n",
    "# Skip over all of the training + validation samples, the rest remain as samples for testing\n",
    "test_ds = ds.skip(n_train_samples + n_val_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f58977-6973-4445-9a9c-0ee2880e6950",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffling just the training data  \n",
    "train_ds  = train_ds.shuffle(buffer_size = len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf13d7-46c1-4c41-b983-d7c8d23accf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Setting the batch_size for all datasets\n",
    "BATCH_SIZE = 32\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE)\n",
    "# Confirm the number of batches in each\n",
    "print (f' There are {len(train_ds)} training batches.')\n",
    "print (f' There are {len(val_ds)} validation batches.')\n",
    "print (f' There are {len(test_ds)} testing batches.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca36702-26f2-46cc-88cf-79e752a3e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get just the text from ds_train\n",
    "ds_texts = train_ds.map(lambda x, y: x)\n",
    "# Preview the text\n",
    "ds_texts.take(1).get_single_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608ce6ba-ea72-45bd-938b-0fce6e65f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create text Vectorization layer\n",
    "sequence_vectorizer = tf.keras.layers.TextVectorization(\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=100\n",
    ")\n",
    "sequence_vectorizer.adapt(ds_texts)\n",
    "sequence_vectorizer.vocabulary_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b713db4f-5b56-442b-bf4c-595a6e224d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting list of vocab\n",
    "vocab = sequence_vectorizer.get_vocabulary()\n",
    "int_to_str = {idx: word for idx, word in enumerate(vocab)}\n",
    "int_to_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d55351-eb1c-431e-8a8b-58ee2fce1f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_str[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46caf21b-c1d9-4eb1-b14a-8b1894fff8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the sequence of sample text with the sequence_vectorizer\n",
    "sequence= sequence_vectorizer([\"Text Vectorization is an essential tool for converting text into a format that machine learning models can use.\"])\n",
    "sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f0ac51-b6ba-4432-8e1f-276d9b6d086a",
   "metadata": {},
   "source": [
    "# Text Classification with RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c2ecab-3780-4007-a536-39e6987288d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
