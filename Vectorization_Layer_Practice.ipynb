{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b4a2086-9d28-4186-adbe-604cdac5c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# Then Set Random Seeds\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "# Then run the Enable Deterministic Operations Function\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0bb6658-c527-4507-bcd6-dd8238f0f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')\n",
    "pd.set_option('display.max_colwidth', 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b44eb4-e4ec-48f3-8e83-c94f12eb56dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "def classification_metrics(y_true, y_pred, label='',\n",
    "                           output_dict=False, figsize=(8,4),\n",
    "                           normalize='true', cmap='Blues',\n",
    "                           colorbar=False,values_format=\".2f\"):\n",
    "    \"\"\"Modified version of classification metrics function from Intro to Machine Learning.\n",
    "    Updates:\n",
    "    - Reversed raw counts confusion matrix cmap  (so darker==more).\n",
    "    - Added arg for normalized confusion matrix values_format\n",
    "    \"\"\"\n",
    "    # Get the classification report\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    \n",
    "    ## Print header and report\n",
    "    header = \"-\"*70\n",
    "    print(header, f\" Classification Metrics: {label}\", header, sep='\\n')\n",
    "    print(report)\n",
    "    \n",
    "    ## CONFUSION MATRICES SUBPLOTS\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=figsize)\n",
    "    \n",
    "    # Create a confusion matrix  of raw counts (left subplot)\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                                            normalize=None, \n",
    "                                            cmap='gist_gray_r',# Updated cmap\n",
    "                                            values_format=\"d\", \n",
    "                                            colorbar=colorbar,\n",
    "                                            ax = axes[0]);\n",
    "    axes[0].set_title(\"Raw Counts\")\n",
    "    \n",
    "    # Create a confusion matrix with the data with normalize argument \n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                                            normalize=normalize,\n",
    "                                            cmap=cmap, \n",
    "                                            values_format=values_format, #New arg\n",
    "                                            colorbar=colorbar,\n",
    "                                            ax = axes[1]);\n",
    "    axes[1].set_title(\"Normalized Confusion Matrix\")\n",
    "    \n",
    "    # Adjust layout and show figure\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return dictionary of classification_report\n",
    "    if output_dict==True:\n",
    "        report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "        return report_dict\n",
    "    \n",
    "    \n",
    "def evaluate_classification(model, X_train, y_train, X_test, y_test,\n",
    "                         figsize=(6,4), normalize='true', output_dict = False,\n",
    "                            cmap_train='Blues', cmap_test=\"Reds\",colorbar=False):\n",
    "  # Get predictions for training data\n",
    "  y_train_pred = model.predict(X_train)\n",
    "  # Call the helper function to obtain regression metrics for training data\n",
    "  results_train = classification_metrics(y_train, y_train_pred, #verbose = verbose,\n",
    "                                     output_dict=True, figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_train,\n",
    "                                     label='Training Data')\n",
    "  print()\n",
    "  # Get predictions for test data\n",
    "  y_test_pred = model.predict(X_test)\n",
    "  # Call the helper function to obtain regression metrics for test data\n",
    "  results_test = classification_metrics(y_test, y_test_pred, #verbose = verbose,\n",
    "                                  output_dict=True,figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_test,\n",
    "                                    label='Test Data' )\n",
    "  if output_dict == True:\n",
    "    # Store results in a dataframe if ouput_frame is True\n",
    "    results_dict = {'train':results_train,\n",
    "                    'test': results_test}\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd3fc5b-5ab4-4cd1-8bd2-19e2d4dc8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function for preprocessing texts\n",
    "def batch_preprocess_texts(\n",
    "    texts,\n",
    "    nlp=None,\n",
    "    remove_stopwords=True,\n",
    "    remove_punct=True,\n",
    "    use_lemmas=False,\n",
    "    disable=[\"ner\"],\n",
    "    batch_size=50,\n",
    "    n_process=-1,\n",
    "):\n",
    "    \"\"\"Efficiently preprocess a collection of texts using nlp.pipe()\n",
    "\n",
    "    Args:\n",
    "        texts (collection of strings): collection of texts to process (e.g. df['text'])\n",
    "        nlp (spacy pipe), optional): Spacy nlp pipe. Defaults to None; if None, it creates a default 'en_core_web_sm' pipe.\n",
    "        remove_stopwords (bool, optional): Controls stopword removal. Defaults to True.\n",
    "        remove_punct (bool, optional): Controls punctuation removal. Defaults to True.\n",
    "        use_lemmas (bool, optional): lemmatize tokens. Defaults to False.\n",
    "        disable (list of strings, optional): named pipeline elements to disable. Defaults to [\"ner\"]: Used with nlp.pipe(disable=disable)\n",
    "        batch_size (int, optional): Number of texts to process in a batch. Defaults to 50.\n",
    "        n_process (int, optional): Number of CPU processors to use. Defaults to -1 (meaning all CPU cores).\n",
    "\n",
    "    Returns:\n",
    "        list of tokens\n",
    "    \"\"\"\n",
    "    # from tqdm.notebook import tqdm\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    if nlp is None:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    processed_texts = []\n",
    "\n",
    "    for doc in tqdm(nlp.pipe(texts, disable=disable, batch_size=batch_size, n_process=n_process)):\n",
    "        tokens = []\n",
    "        for token in doc:\n",
    "            # Check if should remove stopwords and if token is stopword\n",
    "            if (remove_stopwords == True) and (token.is_stop == True):\n",
    "                # Continue the loop with the next token\n",
    "                continue\n",
    "\n",
    "            # Check if should remove stopwords and if token is stopword\n",
    "            if (remove_punct == True) and (token.is_punct == True):\n",
    "                continue\n",
    "\n",
    "            # Check if should remove stopwords and if token is stopword\n",
    "            if (remove_punct == True) and (token.is_space == True):\n",
    "                continue\n",
    "\n",
    "            \n",
    "            ## Determine final form of output list of tokens/lemmas\n",
    "            if use_lemmas:\n",
    "                tokens.append(token.lemma_.lower())\n",
    "            else:\n",
    "                tokens.append(token.text.lower())\n",
    "\n",
    "        processed_texts.append(tokens)\n",
    "    return processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33d21bdc-f2d8-44ae-9744-daa474221603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling might be a mere mistake.</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                            text  \\\n",
       "id                                                                                                                                                                                                                                                 \n",
       "id26305  This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.   \n",
       "id17569                                                                                                                                                                  It never once occurred to me that the fumbling might be a mere mistake.   \n",
       "id11008                                 In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.   \n",
       "id27763                           How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.   \n",
       "id12958                                                           Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.   \n",
       "\n",
       "        author  \n",
       "id              \n",
       "id26305    EAP  \n",
       "id17569    HPL  \n",
       "id11008    EAP  \n",
       "id27763    MWS  \n",
       "id12958    HPL  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in horror author data\n",
    "df = pd.read_csv(\"Data/spooky.csv\", index_col = \"id\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2650faf-182f-4b57-a7b0-99b83b31779a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 19579 entries, id26305 to id00393\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    19579 non-null  object\n",
      " 1   author  19579 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 458.9+ KB\n",
      "Duplicate count: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking nulls and duplicates\n",
    "df.info()\n",
    "print(f'Duplicate count: {df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6847d16-1784-4f02-bc77-8a222f61d218",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9814214-c05a-408c-81aa-486172d0adc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "# additional imports needed\n",
    "from nltk.probability import FreqDist\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1ff4c2e-1f0d-4882-913c-0e471a740e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'attribute_ruler', 'lemmatizer']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use spacy to make a tokens columns using appropriate components\n",
    "nlp_light = spacy.load(\"en_core_web_sm\", disable=['parser','ner'])\n",
    "# Print active components\n",
    "nlp_light.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a64af059-0f34-46f5-88b9-6452bc4cc722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19579it [00:40, 488.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[process, afforded, means, ascertaining, dimensions, dungeon, circuit, return, point, set, aware, fact, perfectly, uniform, wall]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling might be a mere mistake.</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[occurred, fumbling, mere, mistake]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[left, hand, gold, snuff, box, capered, hill, cutting, manner, fantastic, steps, took, snuff, incessantly, air, greatest, possible, self, satisfaction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[lovely, spring, looked, windsor, terrace, sixteen, fertile, counties, spread, beneath, speckled, happy, cottages, wealthier, towns, looked, years, heart, cheering, fair]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[finding, gold, superintendent, abandoned, attempts, perplexed, look, occasionally, steals, countenance, sits, thinking, desk]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                            text  \\\n",
       "id                                                                                                                                                                                                                                                 \n",
       "id26305  This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.   \n",
       "id17569                                                                                                                                                                  It never once occurred to me that the fumbling might be a mere mistake.   \n",
       "id11008                                 In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.   \n",
       "id27763                           How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.   \n",
       "id12958                                                           Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.   \n",
       "\n",
       "        author  \\\n",
       "id               \n",
       "id26305    EAP   \n",
       "id17569    HPL   \n",
       "id11008    EAP   \n",
       "id27763    MWS   \n",
       "id12958    HPL   \n",
       "\n",
       "                                                                                                                                                                             tokens  \n",
       "id                                                                                                                                                                                   \n",
       "id26305                                           [process, afforded, means, ascertaining, dimensions, dungeon, circuit, return, point, set, aware, fact, perfectly, uniform, wall]  \n",
       "id17569                                                                                                                                         [occurred, fumbling, mere, mistake]  \n",
       "id11008                     [left, hand, gold, snuff, box, capered, hill, cutting, manner, fantastic, steps, took, snuff, incessantly, air, greatest, possible, self, satisfaction]  \n",
       "id27763  [lovely, spring, looked, windsor, terrace, sixteen, fertile, counties, spread, beneath, speckled, happy, cottages, wealthier, towns, looked, years, heart, cheering, fair]  \n",
       "id12958                                              [finding, gold, superintendent, abandoned, attempts, perplexed, look, occasionally, steals, countenance, sits, thinking, desk]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using custom function to preprocess our text column into tokens\n",
    "df['tokens'] = batch_preprocess_texts(df['text'], nlp = nlp_light)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a3352a0-247f-4eb6-a863-be0d1a3a2563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19579it [00:39, 493.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[process, afforded, means, ascertaining, dimensions, dungeon, circuit, return, point, set, aware, fact, perfectly, uniform, wall]</td>\n",
       "      <td>[process, afford, mean, ascertain, dimension, dungeon, circuit, return, point, set, aware, fact, perfectly, uniform, wall]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling might be a mere mistake.</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[occurred, fumbling, mere, mistake]</td>\n",
       "      <td>[occur, fumbling, mere, mistake]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[left, hand, gold, snuff, box, capered, hill, cutting, manner, fantastic, steps, took, snuff, incessantly, air, greatest, possible, self, satisfaction]</td>\n",
       "      <td>[left, hand, gold, snuff, box, caper, hill, cut, manner, fantastic, step, take, snuff, incessantly, air, great, possible, self, satisfaction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[lovely, spring, looked, windsor, terrace, sixteen, fertile, counties, spread, beneath, speckled, happy, cottages, wealthier, towns, looked, years, heart, cheering, fair]</td>\n",
       "      <td>[lovely, spring, look, windsor, terrace, sixteen, fertile, county, spread, beneath, speckle, happy, cottage, wealthy, town, look, year, heart, cheering, fair]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[finding, gold, superintendent, abandoned, attempts, perplexed, look, occasionally, steals, countenance, sits, thinking, desk]</td>\n",
       "      <td>[find, gold, superintendent, abandon, attempt, perplexed, look, occasionally, steal, countenance, sit, think, desk]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                            text  \\\n",
       "id                                                                                                                                                                                                                                                 \n",
       "id26305  This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.   \n",
       "id17569                                                                                                                                                                  It never once occurred to me that the fumbling might be a mere mistake.   \n",
       "id11008                                 In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.   \n",
       "id27763                           How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.   \n",
       "id12958                                                           Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.   \n",
       "\n",
       "        author  \\\n",
       "id               \n",
       "id26305    EAP   \n",
       "id17569    HPL   \n",
       "id11008    EAP   \n",
       "id27763    MWS   \n",
       "id12958    HPL   \n",
       "\n",
       "                                                                                                                                                                             tokens  \\\n",
       "id                                                                                                                                                                                    \n",
       "id26305                                           [process, afforded, means, ascertaining, dimensions, dungeon, circuit, return, point, set, aware, fact, perfectly, uniform, wall]   \n",
       "id17569                                                                                                                                         [occurred, fumbling, mere, mistake]   \n",
       "id11008                     [left, hand, gold, snuff, box, capered, hill, cutting, manner, fantastic, steps, took, snuff, incessantly, air, greatest, possible, self, satisfaction]   \n",
       "id27763  [lovely, spring, looked, windsor, terrace, sixteen, fertile, counties, spread, beneath, speckled, happy, cottages, wealthier, towns, looked, years, heart, cheering, fair]   \n",
       "id12958                                              [finding, gold, superintendent, abandoned, attempts, perplexed, look, occasionally, steals, countenance, sits, thinking, desk]   \n",
       "\n",
       "                                                                                                                                                                 lemmas  \n",
       "id                                                                                                                                                                       \n",
       "id26305                                      [process, afford, mean, ascertain, dimension, dungeon, circuit, return, point, set, aware, fact, perfectly, uniform, wall]  \n",
       "id17569                                                                                                                                [occur, fumbling, mere, mistake]  \n",
       "id11008                   [left, hand, gold, snuff, box, caper, hill, cut, manner, fantastic, step, take, snuff, incessantly, air, great, possible, self, satisfaction]  \n",
       "id27763  [lovely, spring, look, windsor, terrace, sixteen, fertile, county, spread, beneath, speckle, happy, cottage, wealthy, town, look, year, heart, cheering, fair]  \n",
       "id12958                                             [find, gold, superintendent, abandon, attempt, perplexed, look, occasionally, steal, countenance, sit, think, desk]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch preprocess the text and store lemmas\n",
    "df['lemmas'] = batch_preprocess_texts(df['text'], nlp = nlp_light, use_lemmas = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80b83c2e-3d8d-474b-8d8e-fc6e819d9fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>tokens-joined</th>\n",
       "      <th>lemmas-joined</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[process, afforded, means, ascertaining, dimensions, dungeon, circuit, return, point, set, aware, fact, perfectly, uniform, wall]</td>\n",
       "      <td>[process, afford, mean, ascertain, dimension, dungeon, circuit, return, point, set, aware, fact, perfectly, uniform, wall]</td>\n",
       "      <td>process afforded means ascertaining dimensions dungeon circuit return point set aware fact perfectly uniform wall</td>\n",
       "      <td>process afford mean ascertain dimension dungeon circuit return point set aware fact perfectly uniform wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling might be a mere mistake.</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[occurred, fumbling, mere, mistake]</td>\n",
       "      <td>[occur, fumbling, mere, mistake]</td>\n",
       "      <td>occurred fumbling mere mistake</td>\n",
       "      <td>occur fumbling mere mistake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[left, hand, gold, snuff, box, capered, hill, cutting, manner, fantastic, steps, took, snuff, incessantly, air, greatest, possible, self, satisfaction]</td>\n",
       "      <td>[left, hand, gold, snuff, box, caper, hill, cut, manner, fantastic, step, take, snuff, incessantly, air, great, possible, self, satisfaction]</td>\n",
       "      <td>left hand gold snuff box capered hill cutting manner fantastic steps took snuff incessantly air greatest possible self satisfaction</td>\n",
       "      <td>left hand gold snuff box caper hill cut manner fantastic step take snuff incessantly air great possible self satisfaction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                            text  \\\n",
       "id                                                                                                                                                                                                                                                 \n",
       "id26305  This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.   \n",
       "id17569                                                                                                                                                                  It never once occurred to me that the fumbling might be a mere mistake.   \n",
       "id11008                                 In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.   \n",
       "\n",
       "        author  \\\n",
       "id               \n",
       "id26305    EAP   \n",
       "id17569    HPL   \n",
       "id11008    EAP   \n",
       "\n",
       "                                                                                                                                                          tokens  \\\n",
       "id                                                                                                                                                                 \n",
       "id26305                        [process, afforded, means, ascertaining, dimensions, dungeon, circuit, return, point, set, aware, fact, perfectly, uniform, wall]   \n",
       "id17569                                                                                                                      [occurred, fumbling, mere, mistake]   \n",
       "id11008  [left, hand, gold, snuff, box, capered, hill, cutting, manner, fantastic, steps, took, snuff, incessantly, air, greatest, possible, self, satisfaction]   \n",
       "\n",
       "                                                                                                                                                lemmas  \\\n",
       "id                                                                                                                                                       \n",
       "id26305                     [process, afford, mean, ascertain, dimension, dungeon, circuit, return, point, set, aware, fact, perfectly, uniform, wall]   \n",
       "id17569                                                                                                               [occur, fumbling, mere, mistake]   \n",
       "id11008  [left, hand, gold, snuff, box, caper, hill, cut, manner, fantastic, step, take, snuff, incessantly, air, great, possible, self, satisfaction]   \n",
       "\n",
       "                                                                                                                               tokens-joined  \\\n",
       "id                                                                                                                                             \n",
       "id26305                    process afforded means ascertaining dimensions dungeon circuit return point set aware fact perfectly uniform wall   \n",
       "id17569                                                                                                       occurred fumbling mere mistake   \n",
       "id11008  left hand gold snuff box capered hill cutting manner fantastic steps took snuff incessantly air greatest possible self satisfaction   \n",
       "\n",
       "                                                                                                                     lemmas-joined  \n",
       "id                                                                                                                                  \n",
       "id26305                 process afford mean ascertain dimension dungeon circuit return point set aware fact perfectly uniform wall  \n",
       "id17569                                                                                                occur fumbling mere mistake  \n",
       "id11008  left hand gold snuff box caper hill cut manner fantastic step take snuff incessantly air great possible self satisfaction  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join list of tokens into a string with spaces between each token\n",
    "df['tokens-joined'] = df['tokens'].map(lambda x: \" \".join(x))\n",
    "# Join list of lemmas into a string with spaces between each lemma\n",
    "df['lemmas-joined'] = df['lemmas'].map(lambda x: \" \".join(x))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8788803-cf7b-40b9-993c-d8114b2bc587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>tokens-joined</th>\n",
       "      <th>lemmas-joined</th>\n",
       "      <th>wc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id26305</th>\n",
       "      <td>This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[process, afforded, means, ascertaining, dimensions, dungeon, circuit, return, point, set, aware, fact, perfectly, uniform, wall]</td>\n",
       "      <td>[process, afford, mean, ascertain, dimension, dungeon, circuit, return, point, set, aware, fact, perfectly, uniform, wall]</td>\n",
       "      <td>process afforded means ascertaining dimensions dungeon circuit return point set aware fact perfectly uniform wall</td>\n",
       "      <td>process afford mean ascertain dimension dungeon circuit return point set aware fact perfectly uniform wall</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id17569</th>\n",
       "      <td>It never once occurred to me that the fumbling might be a mere mistake.</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[occurred, fumbling, mere, mistake]</td>\n",
       "      <td>[occur, fumbling, mere, mistake]</td>\n",
       "      <td>occurred fumbling mere mistake</td>\n",
       "      <td>occur fumbling mere mistake</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id11008</th>\n",
       "      <td>In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.</td>\n",
       "      <td>EAP</td>\n",
       "      <td>[left, hand, gold, snuff, box, capered, hill, cutting, manner, fantastic, steps, took, snuff, incessantly, air, greatest, possible, self, satisfaction]</td>\n",
       "      <td>[left, hand, gold, snuff, box, caper, hill, cut, manner, fantastic, step, take, snuff, incessantly, air, great, possible, self, satisfaction]</td>\n",
       "      <td>left hand gold snuff box capered hill cutting manner fantastic steps took snuff incessantly air greatest possible self satisfaction</td>\n",
       "      <td>left hand gold snuff box caper hill cut manner fantastic step take snuff incessantly air great possible self satisfaction</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id27763</th>\n",
       "      <td>How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.</td>\n",
       "      <td>MWS</td>\n",
       "      <td>[lovely, spring, looked, windsor, terrace, sixteen, fertile, counties, spread, beneath, speckled, happy, cottages, wealthier, towns, looked, years, heart, cheering, fair]</td>\n",
       "      <td>[lovely, spring, look, windsor, terrace, sixteen, fertile, county, spread, beneath, speckle, happy, cottage, wealthy, town, look, year, heart, cheering, fair]</td>\n",
       "      <td>lovely spring looked windsor terrace sixteen fertile counties spread beneath speckled happy cottages wealthier towns looked years heart cheering fair</td>\n",
       "      <td>lovely spring look windsor terrace sixteen fertile county spread beneath speckle happy cottage wealthy town look year heart cheering fair</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id12958</th>\n",
       "      <td>Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.</td>\n",
       "      <td>HPL</td>\n",
       "      <td>[finding, gold, superintendent, abandoned, attempts, perplexed, look, occasionally, steals, countenance, sits, thinking, desk]</td>\n",
       "      <td>[find, gold, superintendent, abandon, attempt, perplexed, look, occasionally, steal, countenance, sit, think, desk]</td>\n",
       "      <td>finding gold superintendent abandoned attempts perplexed look occasionally steals countenance sits thinking desk</td>\n",
       "      <td>find gold superintendent abandon attempt perplexed look occasionally steal countenance sit think desk</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                            text  \\\n",
       "id                                                                                                                                                                                                                                                 \n",
       "id26305  This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.   \n",
       "id17569                                                                                                                                                                  It never once occurred to me that the fumbling might be a mere mistake.   \n",
       "id11008                                 In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction.   \n",
       "id27763                           How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair.   \n",
       "id12958                                                           Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk.   \n",
       "\n",
       "        author  \\\n",
       "id               \n",
       "id26305    EAP   \n",
       "id17569    HPL   \n",
       "id11008    EAP   \n",
       "id27763    MWS   \n",
       "id12958    HPL   \n",
       "\n",
       "                                                                                                                                                                             tokens  \\\n",
       "id                                                                                                                                                                                    \n",
       "id26305                                           [process, afforded, means, ascertaining, dimensions, dungeon, circuit, return, point, set, aware, fact, perfectly, uniform, wall]   \n",
       "id17569                                                                                                                                         [occurred, fumbling, mere, mistake]   \n",
       "id11008                     [left, hand, gold, snuff, box, capered, hill, cutting, manner, fantastic, steps, took, snuff, incessantly, air, greatest, possible, self, satisfaction]   \n",
       "id27763  [lovely, spring, looked, windsor, terrace, sixteen, fertile, counties, spread, beneath, speckled, happy, cottages, wealthier, towns, looked, years, heart, cheering, fair]   \n",
       "id12958                                              [finding, gold, superintendent, abandoned, attempts, perplexed, look, occasionally, steals, countenance, sits, thinking, desk]   \n",
       "\n",
       "                                                                                                                                                                 lemmas  \\\n",
       "id                                                                                                                                                                        \n",
       "id26305                                      [process, afford, mean, ascertain, dimension, dungeon, circuit, return, point, set, aware, fact, perfectly, uniform, wall]   \n",
       "id17569                                                                                                                                [occur, fumbling, mere, mistake]   \n",
       "id11008                   [left, hand, gold, snuff, box, caper, hill, cut, manner, fantastic, step, take, snuff, incessantly, air, great, possible, self, satisfaction]   \n",
       "id27763  [lovely, spring, look, windsor, terrace, sixteen, fertile, county, spread, beneath, speckle, happy, cottage, wealthy, town, look, year, heart, cheering, fair]   \n",
       "id12958                                             [find, gold, superintendent, abandon, attempt, perplexed, look, occasionally, steal, countenance, sit, think, desk]   \n",
       "\n",
       "                                                                                                                                                 tokens-joined  \\\n",
       "id                                                                                                                                                               \n",
       "id26305                                      process afforded means ascertaining dimensions dungeon circuit return point set aware fact perfectly uniform wall   \n",
       "id17569                                                                                                                         occurred fumbling mere mistake   \n",
       "id11008                    left hand gold snuff box capered hill cutting manner fantastic steps took snuff incessantly air greatest possible self satisfaction   \n",
       "id27763  lovely spring looked windsor terrace sixteen fertile counties spread beneath speckled happy cottages wealthier towns looked years heart cheering fair   \n",
       "id12958                                       finding gold superintendent abandoned attempts perplexed look occasionally steals countenance sits thinking desk   \n",
       "\n",
       "                                                                                                                                     lemmas-joined  \\\n",
       "id                                                                                                                                                   \n",
       "id26305                                 process afford mean ascertain dimension dungeon circuit return point set aware fact perfectly uniform wall   \n",
       "id17569                                                                                                                occur fumbling mere mistake   \n",
       "id11008                  left hand gold snuff box caper hill cut manner fantastic step take snuff incessantly air great possible self satisfaction   \n",
       "id27763  lovely spring look windsor terrace sixteen fertile county spread beneath speckle happy cottage wealthy town look year heart cheering fair   \n",
       "id12958                                      find gold superintendent abandon attempt perplexed look occasionally steal countenance sit think desk   \n",
       "\n",
       "         wc  \n",
       "id           \n",
       "id26305  15  \n",
       "id17569   4  \n",
       "id11008  19  \n",
       "id27763  20  \n",
       "id12958  13  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making new column to find the average word count for real and fake news articles\n",
    "df['wc'] = df['tokens'].apply(lambda x: len(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e029e81d-88ac-4f4e-892d-564699a9c6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting average tokens for horror lines\n",
    "df['wc'].mean().round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "335de847-9a4e-4995-9244-f63d52c93c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7900\n",
       "2    6044\n",
       "1    5635\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to change our target to integers for modeling. Changing EAP to 0, HPL to 1, MWS to 2.\n",
    "df['author'] = df['author'].replace(\"EAP\", 0).replace(\"HPL\", 1).replace(\"MWS\", 2)\n",
    "df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caf3a6fc-807f-476c-88fe-b59ab9e0bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking balance of our target author columns\n",
    "y = df['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "321ba8fd-7e1e-481e-a0c8-a597d3ec879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "368d8e7a-aa6c-4d9f-b68f-cb2191e9737e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.333333\n",
       "1    0.333333\n",
       "2    0.333333\n",
       "Name: author, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resampling\n",
    "sampler = RandomUnderSampler(random_state = 42)\n",
    "X_res, y_res = sampler.fit_resample(X.values.reshape(-1,1),y)\n",
    "X_res = X_res.flatten()\n",
    "# Doublechecking class imbalance\n",
    "y_res.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94c56458-23f2-43fa-9236-f4343954e67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to Dataset object\n",
    "ds = tf.data.Dataset.from_tensor_slices((X_res, y_res))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b11e3ed3-cb1a-4438-b406-f6c493b50d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling the data once\n",
    "ds = ds.shuffle(buffer_size=len(ds), reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed7685e6-9b4f-4bcd-8597-6726da60a85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use 11833 samples as training data\n",
      "Use 3381 samples as validation data\n",
      "The remaining 1691 samples will be used as test data.\n"
     ]
    }
   ],
   "source": [
    "# Determing how many samples for each split\n",
    "# Calculate the number of samples for training \n",
    "split_train = 0.7\n",
    "n_train_samples =  int(len(ds) * split_train)\n",
    "print(f\"Use {n_train_samples} samples as training data\")\n",
    "# Calculate the number of samples for validation\n",
    "split_val = 0.2\n",
    "n_val_samples = int(len(ds) * split_val)\n",
    "print(f\"Use {n_val_samples} samples as validation data\")\n",
    "# Test size is remainder\n",
    "split_test = 1 - (split_train + split_val)\n",
    "print(f\"The remaining {len(ds)- (n_train_samples+n_val_samples)} samples will be used as test data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4517e49a-4e40-4b3b-ae4c-ccb3505d42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .take to slice out the number of samples for training\n",
    "train_ds = ds.take(n_train_samples)\n",
    "# Skipover the training batches\n",
    "val_ds = ds.skip(n_train_samples)\n",
    "# Take .take to slice out the correct number of samples for validation\n",
    "val_ds = val_ds.take(n_val_samples)\n",
    "# Skip over all of the training + validation samples, the rest remain as samples for testing\n",
    "test_ds = ds.skip(n_train_samples + n_val_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7f58977-6973-4445-9a9c-0ee2880e6950",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffling just the training data  \n",
    "train_ds  = train_ds.shuffle(buffer_size = len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acbf13d7-46c1-4c41-b983-d7c8d23accf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are 370 training batches.\n",
      " There are 106 validation batches.\n",
      " There are 53 testing batches.\n"
     ]
    }
   ],
   "source": [
    "#  Setting the batch_size for all datasets\n",
    "BATCH_SIZE = 32\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE)\n",
    "# Confirm the number of batches in each\n",
    "print (f' There are {len(train_ds)} training batches.')\n",
    "print (f' There are {len(val_ds)} validation batches.')\n",
    "print (f' There are {len(test_ds)} testing batches.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ca36702-26f2-46cc-88cf-79e752a3e86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=string, numpy=\n",
       "array([b'This was a glorious winter.',\n",
       "       b'He had told her no more than he had told the public, but had left a long manuscript of \"technical matters\" as he said written in English, evidently in order to safeguard her from the peril of casual perusal.',\n",
       "       b'A nervous fever was the consequence; during which he was nursed by the daughter of a poor cottager, under whose roof he lodged.',\n",
       "       b\"I had before visited the manor houses and gentlemen's seats, and often found the inhabitants actuated by the purest benevolence, ready to lend their utmost aid for the welfare of their tenants.\",\n",
       "       b'The panic struck appeared of more injury, than disease and its natural concomitants.',\n",
       "       b'Each vessel in the mean time brought exhilarating tidings from Greece.',\n",
       "       b'Therein were written many things concerning the world of dream, and among them was lore of a golden valley and a sacred grove with temples, and a high wall pierced by a little bronze gate.',\n",
       "       b'There was a brief silence, and in that pause the scattered senses of poor Curtis Whateley began to knit back into a sort of continuity; so that he put his hands to his head with a moan.',\n",
       "       b'Me feered de bug what I keer for de bug?\"',\n",
       "       b'the, or, substituting the natural letters, where known, it reads thus: the tree thr?h the.',\n",
       "       b'I reply that I know nothing beyond what I saw.',\n",
       "       b'His design was to visit India, in the belief that he had in his knowledge of its various languages, and in the views he had taken of its society, the means of materially assisting the progress of European colonization and trade.',\n",
       "       b'The abode of the race whose scions are here inurned had once crowned the declivity which holds the tomb, but had long since fallen victim to the flames which sprang up from a disastrous stroke of lightning.',\n",
       "       b'And now he was equally resentful of awaking, for he had found his fabulous city after forty weary years.',\n",
       "       b\"Even when a cannon is fired over a corpse, and it rises before at least five or six days' immersion, it sinks again if let alone.'\",\n",
       "       b'There is nothing more lovely, to which the heart more yearns than a free spirited boy, gentle, brave, and generous.',\n",
       "       b'My beloved friends were alarmed nay, they expressed their alarm so anxiously, that I dared not pronounce the word plague, that hovered on my lips, lest they should construe my perturbed looks into a symptom, and see infection in my languor.',\n",
       "       b\"She and her brother were not so much interested in the house as was Archer's son Carrington, the present owner, with whom I talked after my experience.\",\n",
       "       b'There was no external door to the north wing, and it also had only one window to the east.',\n",
       "       b'But what mainly disturbed me was the idea that had perceptibly descended.',\n",
       "       b'His end had plainly forgotten his beginning, like the government of Trinculo.',\n",
       "       b'And if these were my sensations, who can describe those of Henry?',\n",
       "       b'In the chaos of sliding, shifting earth I clawed and floundered helplessly till the rain on my head steadied me and I saw that I had come to the surface in a familiar spot; a steep unforested place on the southwest slope of the mountain.',\n",
       "       b'In person, he is short and stout, with large, fat, blue eyes, sandy hair and whiskers, a wide but pleasing mouth, fine teeth, and I think a Roman nose.',\n",
       "       b'Detectives have questioned me, but what can I say?',\n",
       "       b'If he were vanquished, I should be a free man.',\n",
       "       b'What would happen on reanimation, and whether we could hope for a revival of mind and reason, West did not venture to predict.',\n",
       "       b'My rage was unbounded, yet my German sense forbade me to venture unprepared into an utterly black interior which might prove the lair of some indescribable marine monster or a labyrinth of passages from whose windings I could never extricate myself.',\n",
       "       b'Of its origin, apart from the erratic and unbelievable tales extorted from the captured members, absolutely nothing was to be discovered; hence the anxiety of the police for any antiquarian lore which might help them to place the frightful symbol, and through it track down the cult to its fountain head.',\n",
       "       b'\"As soon as the balloon quits the earth, it is subjected to the influence of many circumstances tending to create a difference in its weight; augmenting or diminishing its ascending power.',\n",
       "       b'She looked steadily on life and assumed its duties with courage and zeal.',\n",
       "       b'Besides, has he not had his full share of the blessings of mortality?'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get just the text from ds_train\n",
    "ds_texts = train_ds.map(lambda x, y: x)\n",
    "# Preview the text\n",
    "ds_texts.take(1).get_single_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "608ce6ba-ea72-45bd-938b-0fce6e65f8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20976"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text Vectorization layer\n",
    "sequence_vectorizer = tf.keras.layers.TextVectorization(\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=100\n",
    ")\n",
    "sequence_vectorizer.adapt(ds_texts)\n",
    "sequence_vectorizer.vocabulary_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b713db4f-5b56-442b-bf4c-595a6e224d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '',\n",
       " 1: '[UNK]',\n",
       " 2: 'the',\n",
       " 3: 'of',\n",
       " 4: 'and',\n",
       " 5: 'to',\n",
       " 6: 'i',\n",
       " 7: 'a',\n",
       " 8: 'in',\n",
       " 9: 'was',\n",
       " 10: 'that',\n",
       " 11: 'my',\n",
       " 12: 'it',\n",
       " 13: 'he',\n",
       " 14: 'had',\n",
       " 15: 'with',\n",
       " 16: 'his',\n",
       " 17: 'as',\n",
       " 18: 'for',\n",
       " 19: 'but',\n",
       " 20: 'which',\n",
       " 21: 'not',\n",
       " 22: 'me',\n",
       " 23: 'at',\n",
       " 24: 'from',\n",
       " 25: 'by',\n",
       " 26: 'on',\n",
       " 27: 'this',\n",
       " 28: 'is',\n",
       " 29: 'her',\n",
       " 30: 'be',\n",
       " 31: 'were',\n",
       " 32: 'have',\n",
       " 33: 'you',\n",
       " 34: 'all',\n",
       " 35: 'an',\n",
       " 36: 'we',\n",
       " 37: 'or',\n",
       " 38: 'no',\n",
       " 39: 'when',\n",
       " 40: 'him',\n",
       " 41: 'one',\n",
       " 42: 'so',\n",
       " 43: 'they',\n",
       " 44: 'been',\n",
       " 45: 'could',\n",
       " 46: 'would',\n",
       " 47: 'she',\n",
       " 48: 'there',\n",
       " 49: 'upon',\n",
       " 50: 'more',\n",
       " 51: 'its',\n",
       " 52: 'their',\n",
       " 53: 'now',\n",
       " 54: 'what',\n",
       " 55: 'some',\n",
       " 56: 'our',\n",
       " 57: 'into',\n",
       " 58: 'if',\n",
       " 59: 'them',\n",
       " 60: 'who',\n",
       " 61: 'are',\n",
       " 62: 'will',\n",
       " 63: 'than',\n",
       " 64: 'then',\n",
       " 65: 'only',\n",
       " 66: 'very',\n",
       " 67: 'up',\n",
       " 68: 'before',\n",
       " 69: 'man',\n",
       " 70: 'about',\n",
       " 71: 'even',\n",
       " 72: 'these',\n",
       " 73: 'out',\n",
       " 74: 'yet',\n",
       " 75: 'your',\n",
       " 76: 'time',\n",
       " 77: 'did',\n",
       " 78: 'any',\n",
       " 79: 'old',\n",
       " 80: 'said',\n",
       " 81: 'might',\n",
       " 82: 'like',\n",
       " 83: 'after',\n",
       " 84: 'over',\n",
       " 85: 'first',\n",
       " 86: 'night',\n",
       " 87: 'life',\n",
       " 88: 'through',\n",
       " 89: 'eyes',\n",
       " 90: 'us',\n",
       " 91: 'must',\n",
       " 92: 'do',\n",
       " 93: 'never',\n",
       " 94: 'most',\n",
       " 95: 'seemed',\n",
       " 96: 'should',\n",
       " 97: 'other',\n",
       " 98: 'found',\n",
       " 99: 'while',\n",
       " 100: 'made',\n",
       " 101: 'such',\n",
       " 102: 'saw',\n",
       " 103: 'great',\n",
       " 104: 'those',\n",
       " 105: 'still',\n",
       " 106: 'day',\n",
       " 107: 'where',\n",
       " 108: 'little',\n",
       " 109: 'every',\n",
       " 110: 'long',\n",
       " 111: 'again',\n",
       " 112: 'myself',\n",
       " 113: 'many',\n",
       " 114: 'down',\n",
       " 115: 'well',\n",
       " 116: 'has',\n",
       " 117: 'came',\n",
       " 118: 'how',\n",
       " 119: 'own',\n",
       " 120: 'much',\n",
       " 121: 'once',\n",
       " 122: 'can',\n",
       " 123: 'may',\n",
       " 124: 'two',\n",
       " 125: 'thought',\n",
       " 126: 'whose',\n",
       " 127: 'ever',\n",
       " 128: 'being',\n",
       " 129: 'death',\n",
       " 130: 'am',\n",
       " 131: 'things',\n",
       " 132: 'see',\n",
       " 133: 'men',\n",
       " 134: 'heard',\n",
       " 135: 'thus',\n",
       " 136: 'heart',\n",
       " 137: 'mind',\n",
       " 138: 'far',\n",
       " 139: 'too',\n",
       " 140: 'thing',\n",
       " 141: 'say',\n",
       " 142: 'know',\n",
       " 143: 'without',\n",
       " 144: 'left',\n",
       " 145: 'house',\n",
       " 146: 'shall',\n",
       " 147: 'though',\n",
       " 148: 'felt',\n",
       " 149: 'last',\n",
       " 150: 'here',\n",
       " 151: 'love',\n",
       " 152: 'come',\n",
       " 153: 'place',\n",
       " 154: 'away',\n",
       " 155: 'himself',\n",
       " 156: 'years',\n",
       " 157: 'became',\n",
       " 158: 'light',\n",
       " 159: 'few',\n",
       " 160: 'world',\n",
       " 161: 'however',\n",
       " 162: 'earth',\n",
       " 163: 'each',\n",
       " 164: 'nor',\n",
       " 165: 'indeed',\n",
       " 166: 'seen',\n",
       " 167: 'way',\n",
       " 168: 'room',\n",
       " 169: 'head',\n",
       " 170: 'words',\n",
       " 171: 'knew',\n",
       " 172: 'back',\n",
       " 173: 'door',\n",
       " 174: 'strange',\n",
       " 175: 'new',\n",
       " 176: 'whole',\n",
       " 177: 'hand',\n",
       " 178: 'human',\n",
       " 179: 'voice',\n",
       " 180: 'under',\n",
       " 181: 'same',\n",
       " 182: 'half',\n",
       " 183: 'fear',\n",
       " 184: 'let',\n",
       " 185: 'beyond',\n",
       " 186: 'nothing',\n",
       " 187: 'make',\n",
       " 188: 'having',\n",
       " 189: 'friend',\n",
       " 190: 'three',\n",
       " 191: 'soon',\n",
       " 192: 'raymond',\n",
       " 193: 'father',\n",
       " 194: 'off',\n",
       " 195: 'good',\n",
       " 196: 'during',\n",
       " 197: 'among',\n",
       " 198: 'length',\n",
       " 199: 'part',\n",
       " 200: 'moment',\n",
       " 201: 'within',\n",
       " 202: 'nature',\n",
       " 203: 'less',\n",
       " 204: 'alone',\n",
       " 205: 'looked',\n",
       " 206: 'since',\n",
       " 207: 'almost',\n",
       " 208: 'small',\n",
       " 209: 'near',\n",
       " 210: 'gave',\n",
       " 211: 'around',\n",
       " 212: 'something',\n",
       " 213: 'sea',\n",
       " 214: 'another',\n",
       " 215: 'told',\n",
       " 216: 'face',\n",
       " 217: 'city',\n",
       " 218: 'appeared',\n",
       " 219: 'went',\n",
       " 220: 'passed',\n",
       " 221: 'air',\n",
       " 222: 'young',\n",
       " 223: 'whom',\n",
       " 224: 'find',\n",
       " 225: 'dark',\n",
       " 226: 'took',\n",
       " 227: 'soul',\n",
       " 228: 'certain',\n",
       " 229: 'although',\n",
       " 230: 'full',\n",
       " 231: 'tell',\n",
       " 232: 'high',\n",
       " 233: 'days',\n",
       " 234: 'also',\n",
       " 235: 'think',\n",
       " 236: 'horror',\n",
       " 237: 'take',\n",
       " 238: 'began',\n",
       " 239: 'above',\n",
       " 240: 'just',\n",
       " 241: 'end',\n",
       " 242: 'body',\n",
       " 243: 'lay',\n",
       " 244: 'dead',\n",
       " 245: 'course',\n",
       " 246: 'black',\n",
       " 247: 'why',\n",
       " 248: 'hope',\n",
       " 249: 'form',\n",
       " 250: 'street',\n",
       " 251: 'o',\n",
       " 252: 'go',\n",
       " 253: 'turned',\n",
       " 254: 'kind',\n",
       " 255: 'towards',\n",
       " 256: 'itself',\n",
       " 257: 'open',\n",
       " 258: 'spirit',\n",
       " 259: 'cannot',\n",
       " 260: 'mr',\n",
       " 261: 'least',\n",
       " 262: 'because',\n",
       " 263: 'water',\n",
       " 264: 'scene',\n",
       " 265: 'point',\n",
       " 266: 'often',\n",
       " 267: 'between',\n",
       " 268: 'sometimes',\n",
       " 269: 'look',\n",
       " 270: 'lost',\n",
       " 271: 'known',\n",
       " 272: 'always',\n",
       " 273: 'until',\n",
       " 274: 'name',\n",
       " 275: 'hours',\n",
       " 276: 'deep',\n",
       " 277: 'ancient',\n",
       " 278: 'feet',\n",
       " 279: 'taken',\n",
       " 280: 'return',\n",
       " 281: 'perhaps',\n",
       " 282: 'against',\n",
       " 283: 'morning',\n",
       " 284: 'white',\n",
       " 285: 'rather',\n",
       " 286: 'hands',\n",
       " 287: 'dream',\n",
       " 288: 'sun',\n",
       " 289: 'present',\n",
       " 290: 'home',\n",
       " 291: 'eye',\n",
       " 292: 'town',\n",
       " 293: 'spoke',\n",
       " 294: 'idea',\n",
       " 295: 'brought',\n",
       " 296: 'both',\n",
       " 297: 'power',\n",
       " 298: 'called',\n",
       " 299: 'stood',\n",
       " 300: 'sight',\n",
       " 301: 'side',\n",
       " 302: 'right',\n",
       " 303: 'put',\n",
       " 304: 'people',\n",
       " 305: 'moon',\n",
       " 306: 'fell',\n",
       " 307: 'thousand',\n",
       " 308: 'speak',\n",
       " 309: 'poor',\n",
       " 310: 'perdita',\n",
       " 311: 'others',\n",
       " 312: 'country',\n",
       " 313: 'object',\n",
       " 314: 'matter',\n",
       " 315: 'terrible',\n",
       " 316: 'floor',\n",
       " 317: 'done',\n",
       " 318: 'change',\n",
       " 319: 'beauty',\n",
       " 320: 'times',\n",
       " 321: 'several',\n",
       " 322: 'person',\n",
       " 323: 'nearly',\n",
       " 324: 'sound',\n",
       " 325: 'grew',\n",
       " 326: 'feel',\n",
       " 327: 'truth',\n",
       " 328: 'means',\n",
       " 329: 'manner',\n",
       " 330: 'give',\n",
       " 331: 'evil',\n",
       " 332: 'entered',\n",
       " 333: 'dreams',\n",
       " 334: 'continued',\n",
       " 335: 'believe',\n",
       " 336: 'west',\n",
       " 337: 'set',\n",
       " 338: 'better',\n",
       " 339: 'become',\n",
       " 340: 'till',\n",
       " 341: 'quite',\n",
       " 342: 'hour',\n",
       " 343: 'true',\n",
       " 344: 'themselves',\n",
       " 345: 'stone',\n",
       " 346: 'sleep',\n",
       " 347: 'read',\n",
       " 348: 'past',\n",
       " 349: 'gone',\n",
       " 350: 'work',\n",
       " 351: 'tears',\n",
       " 352: 'suddenly',\n",
       " 353: 'trees',\n",
       " 354: 'state',\n",
       " 355: 'happy',\n",
       " 356: 'family',\n",
       " 357: 'fact',\n",
       " 358: 'despair',\n",
       " 359: 'case',\n",
       " 360: 'wild',\n",
       " 361: 'second',\n",
       " 362: 'general',\n",
       " 363: 'longer',\n",
       " 364: 'dear',\n",
       " 365: 'possible',\n",
       " 366: 'none',\n",
       " 367: 'adrian',\n",
       " 368: 'thoughts',\n",
       " 369: 'doubt',\n",
       " 370: 'died',\n",
       " 371: 'wonder',\n",
       " 372: 'led',\n",
       " 373: 'happiness',\n",
       " 374: 'de',\n",
       " 375: 'close',\n",
       " 376: 'window',\n",
       " 377: 'walls',\n",
       " 378: 'next',\n",
       " 379: 'ground',\n",
       " 380: 'gentle',\n",
       " 381: 'wish',\n",
       " 382: 'secret',\n",
       " 383: 'remained',\n",
       " 384: 'countenance',\n",
       " 385: 'sense',\n",
       " 386: 'reason',\n",
       " 387: 'idris',\n",
       " 388: 'child',\n",
       " 389: 'already',\n",
       " 390: 'wind',\n",
       " 391: 'god',\n",
       " 392: 'existence',\n",
       " 393: 'evening',\n",
       " 394: 'enough',\n",
       " 395: 'blood',\n",
       " 396: 'word',\n",
       " 397: 'together',\n",
       " 398: 'mother',\n",
       " 399: 'low',\n",
       " 400: 'friends',\n",
       " 401: 'feelings',\n",
       " 402: 'beneath',\n",
       " 403: 'age',\n",
       " 404: 'unknown',\n",
       " 405: 'rest',\n",
       " 406: 'replied',\n",
       " 407: 'large',\n",
       " 408: 'get',\n",
       " 409: 'five',\n",
       " 410: 'character',\n",
       " 411: 'attention',\n",
       " 412: 'appearance',\n",
       " 413: 'wall',\n",
       " 414: 'space',\n",
       " 415: 'sky',\n",
       " 416: 'oh',\n",
       " 417: 'lips',\n",
       " 418: 'hideous',\n",
       " 419: 'feeling',\n",
       " 420: 'england',\n",
       " 421: 'either',\n",
       " 422: 'best',\n",
       " 423: 'behind',\n",
       " 424: 'windows',\n",
       " 425: 'looking',\n",
       " 426: 'late',\n",
       " 427: 'land',\n",
       " 428: 'immediately',\n",
       " 429: 'sat',\n",
       " 430: 'held',\n",
       " 431: 'fellow',\n",
       " 432: 'children',\n",
       " 433: 'therefore',\n",
       " 434: 'period',\n",
       " 435: 'hear',\n",
       " 436: 'given',\n",
       " 437: 'filled',\n",
       " 438: 'along',\n",
       " 439: 'account',\n",
       " 440: 'spot',\n",
       " 441: 'river',\n",
       " 442: 'misery',\n",
       " 443: 'living',\n",
       " 444: 'chamber',\n",
       " 445: 'toward',\n",
       " 446: 'joy',\n",
       " 447: 'imagination',\n",
       " 448: 'short',\n",
       " 449: 'reached',\n",
       " 450: 'cold',\n",
       " 451: 'returned',\n",
       " 452: 'natural',\n",
       " 453: 'mad',\n",
       " 454: 'loved',\n",
       " 455: 'interest',\n",
       " 456: 'followed',\n",
       " 457: 'view',\n",
       " 458: 'sure',\n",
       " 459: 'steps',\n",
       " 460: 'leave',\n",
       " 461: 'knowledge',\n",
       " 462: 'four',\n",
       " 463: 'care',\n",
       " 464: 'vast',\n",
       " 465: 'tried',\n",
       " 466: 'sir',\n",
       " 467: 'neither',\n",
       " 468: 'herself',\n",
       " 469: 'fire',\n",
       " 470: 'early',\n",
       " 471: 'cast',\n",
       " 472: 'arms',\n",
       " 473: 'affection',\n",
       " 474: 'terror',\n",
       " 475: 'question',\n",
       " 476: 'greater',\n",
       " 477: 'gods',\n",
       " 478: 'escape',\n",
       " 479: 'distance',\n",
       " 480: 'youth',\n",
       " 481: 'silence',\n",
       " 482: 'observed',\n",
       " 483: 'north',\n",
       " 484: 'months',\n",
       " 485: 'latter',\n",
       " 486: 'kept',\n",
       " 487: 'bed',\n",
       " 488: 'table',\n",
       " 489: 'memory',\n",
       " 490: 'live',\n",
       " 491: 'letter',\n",
       " 492: 'ill',\n",
       " 493: 'discovered',\n",
       " 494: 'die',\n",
       " 495: 'year',\n",
       " 496: 'self',\n",
       " 497: 'necessary',\n",
       " 498: 'mine',\n",
       " 499: 'hill',\n",
       " 500: 'darkness',\n",
       " 501: 'common',\n",
       " 502: 'coming',\n",
       " 503: 'circumstances',\n",
       " 504: 'caused',\n",
       " 505: 'call',\n",
       " 506: 'beautiful',\n",
       " 507: 'arm',\n",
       " 508: 'across',\n",
       " 509: 'subject',\n",
       " 510: 'really',\n",
       " 511: 'purpose',\n",
       " 512: 'possessed',\n",
       " 513: 'merely',\n",
       " 514: 'heavy',\n",
       " 515: 'heaven',\n",
       " 516: 'green',\n",
       " 517: 'forth',\n",
       " 518: 'dr',\n",
       " 519: 'cause',\n",
       " 520: 'born',\n",
       " 521: 'use',\n",
       " 522: 'thy',\n",
       " 523: 'thou',\n",
       " 524: 'sought',\n",
       " 525: 'six',\n",
       " 526: 'remember',\n",
       " 527: 'received',\n",
       " 528: 'grief',\n",
       " 529: 'various',\n",
       " 530: 'threw',\n",
       " 531: 'save',\n",
       " 532: 'portion',\n",
       " 533: 'pleasure',\n",
       " 534: 'met',\n",
       " 535: 'later',\n",
       " 536: 'excited',\n",
       " 537: 'woman',\n",
       " 538: 'strength',\n",
       " 539: 'scarcely',\n",
       " 540: 'mere',\n",
       " 541: 'line',\n",
       " 542: 'houses',\n",
       " 543: 'formed',\n",
       " 544: 'finally',\n",
       " 545: 'drew',\n",
       " 546: 'beheld',\n",
       " 547: 'ye',\n",
       " 548: 'pain',\n",
       " 549: 'opened',\n",
       " 550: 'native',\n",
       " 551: 'entirely',\n",
       " 552: 'delight',\n",
       " 553: 'cottage',\n",
       " 554: 'wide',\n",
       " 555: 'valley',\n",
       " 556: 'somewhat',\n",
       " 557: 'peculiar',\n",
       " 558: 'instant',\n",
       " 559: 'fancy',\n",
       " 560: 'usual',\n",
       " 561: 'tale',\n",
       " 562: 'streets',\n",
       " 563: 'red',\n",
       " 564: 'outside',\n",
       " 565: 'london',\n",
       " 566: 'lady',\n",
       " 567: 'especially',\n",
       " 568: 'distant',\n",
       " 569: 'degree',\n",
       " 570: 'corpse',\n",
       " 571: 'box',\n",
       " 572: 'wished',\n",
       " 573: 'visible',\n",
       " 574: 'sounds',\n",
       " 575: 'sister',\n",
       " 576: 'rose',\n",
       " 577: 'road',\n",
       " 578: 'got',\n",
       " 579: 'cut',\n",
       " 580: 'calm',\n",
       " 581: 'broken',\n",
       " 582: 'below',\n",
       " 583: 'visit',\n",
       " 584: 'twenty',\n",
       " 585: 'turn',\n",
       " 586: 'ten',\n",
       " 587: 'silent',\n",
       " 588: 'shadow',\n",
       " 589: 'placed',\n",
       " 590: 'hold',\n",
       " 591: 'does',\n",
       " 592: 'book',\n",
       " 593: 'blue',\n",
       " 594: 'asked',\n",
       " 595: 'arrived',\n",
       " 596: 'arose',\n",
       " 597: 'uncle',\n",
       " 598: 'simple',\n",
       " 599: 'round',\n",
       " 600: 'resolved',\n",
       " 601: 'madness',\n",
       " 602: 'lovely',\n",
       " 603: 'lived',\n",
       " 604: 'impossible',\n",
       " 605: 'hills',\n",
       " 606: 'grave',\n",
       " 607: 'faint',\n",
       " 608: 'expression',\n",
       " 609: 'difficulty',\n",
       " 610: 'curious',\n",
       " 611: 'creatures',\n",
       " 612: 'companion',\n",
       " 613: 'closed',\n",
       " 614: 'castle',\n",
       " 615: 'altogether',\n",
       " 616: 'top',\n",
       " 617: 'sweet',\n",
       " 618: 'south',\n",
       " 619: 'horrible',\n",
       " 620: 'fate',\n",
       " 621: 'bring',\n",
       " 622: 'boat',\n",
       " 623: 'spent',\n",
       " 624: 'presence',\n",
       " 625: 'paper',\n",
       " 626: 'mountain',\n",
       " 627: 'keep',\n",
       " 628: 'ice',\n",
       " 629: 'hair',\n",
       " 630: 'east',\n",
       " 631: 'clear',\n",
       " 632: 'books',\n",
       " 633: 'beloved',\n",
       " 634: 'yes',\n",
       " 635: 'whether',\n",
       " 636: 'son',\n",
       " 637: 'slight',\n",
       " 638: 'real',\n",
       " 639: 'odd',\n",
       " 640: 'free',\n",
       " 641: 'force',\n",
       " 642: 'else',\n",
       " 643: 'deserted',\n",
       " 644: 'dared',\n",
       " 645: 'wife',\n",
       " 646: 'want',\n",
       " 647: 'sorrow',\n",
       " 648: 'narrow',\n",
       " 649: 'hardly',\n",
       " 650: 'fully',\n",
       " 651: 'figure',\n",
       " 652: 'events',\n",
       " 653: 'easily',\n",
       " 654: 'creature',\n",
       " 655: 'bore',\n",
       " 656: 'atmosphere',\n",
       " 657: 'ago',\n",
       " 658: 'talked',\n",
       " 659: 'proceeded',\n",
       " 660: 'position',\n",
       " 661: 'party',\n",
       " 662: 'order',\n",
       " 663: 'ocean',\n",
       " 664: 'occurred',\n",
       " 665: 'music',\n",
       " 666: 'mountains',\n",
       " 667: 'marble',\n",
       " 668: 'lord',\n",
       " 669: 'future',\n",
       " 670: 'english',\n",
       " 671: 'effect',\n",
       " 672: 'danger',\n",
       " 673: 'cried',\n",
       " 674: 'changed',\n",
       " 675: 'anything',\n",
       " 676: 'tomb',\n",
       " 677: 'stars',\n",
       " 678: 'singular',\n",
       " 679: 'single',\n",
       " 680: 'shore',\n",
       " 681: 'seized',\n",
       " 682: 'says',\n",
       " 683: 'reality',\n",
       " 684: 'public',\n",
       " 685: 'pale',\n",
       " 686: 'minutes',\n",
       " 687: 'hard',\n",
       " 688: 'grey',\n",
       " 689: 'going',\n",
       " 690: 'frightful',\n",
       " 691: 'fresh',\n",
       " 692: 'forest',\n",
       " 693: 'fallen',\n",
       " 694: 'expected',\n",
       " 695: 'direction',\n",
       " 696: 'courage',\n",
       " 697: 'brain',\n",
       " 698: 'apparently',\n",
       " 699: 'vain',\n",
       " 700: 'thrown',\n",
       " 701: 'thee',\n",
       " 702: 'struck',\n",
       " 703: 'step',\n",
       " 704: 'society',\n",
       " 705: 'progress',\n",
       " 706: 'ones',\n",
       " 707: 'miles',\n",
       " 708: 'hopes',\n",
       " 709: 'forgotten',\n",
       " 710: 'foot',\n",
       " 711: 'elizabeth',\n",
       " 712: 'different',\n",
       " 713: 'condition',\n",
       " 714: 'able',\n",
       " 715: 'windsor',\n",
       " 716: 'utterly',\n",
       " 717: 'story',\n",
       " 718: 'st',\n",
       " 719: 'passion',\n",
       " 720: 'moved',\n",
       " 721: 'influence',\n",
       " 722: 'hidden',\n",
       " 723: 'golden',\n",
       " 724: 'gilman',\n",
       " 725: 'former',\n",
       " 726: 'fears',\n",
       " 727: 'dare',\n",
       " 728: 'boy',\n",
       " 729: 'beings',\n",
       " 730: 'approached',\n",
       " 731: 'absence',\n",
       " 732: 'whilst',\n",
       " 733: 'third',\n",
       " 734: 'strong',\n",
       " 735: 'plague',\n",
       " 736: 'persons',\n",
       " 737: 'perceived',\n",
       " 738: 'passage',\n",
       " 739: 'objects',\n",
       " 740: 'motion',\n",
       " 741: 'miserable',\n",
       " 742: 'mean',\n",
       " 743: 'making',\n",
       " 744: 'journey',\n",
       " 745: 'girl',\n",
       " 746: 'frame',\n",
       " 747: 'fine',\n",
       " 748: 'describe',\n",
       " 749: 'art',\n",
       " 750: 'watched',\n",
       " 751: 'walked',\n",
       " 752: 'tree',\n",
       " 753: 'task',\n",
       " 754: 'taking',\n",
       " 755: 'storm',\n",
       " 756: 'sort',\n",
       " 757: 'ship',\n",
       " 758: 'seek',\n",
       " 759: 'rise',\n",
       " 760: 'remote',\n",
       " 761: 'rain',\n",
       " 762: 'quickly',\n",
       " 763: 'path',\n",
       " 764: 'pass',\n",
       " 765: 'midnight',\n",
       " 766: 'main',\n",
       " 767: 'health',\n",
       " 768: 'fall',\n",
       " 769: 'exceedingly',\n",
       " 770: 'evidently',\n",
       " 771: 'curiosity',\n",
       " 772: 'besides',\n",
       " 773: 'alive',\n",
       " 774: 'action',\n",
       " 775: 'act',\n",
       " 776: 'wood',\n",
       " 777: 'winter',\n",
       " 778: 'understand',\n",
       " 779: 'summer',\n",
       " 780: 'sudden',\n",
       " 781: 'rendered',\n",
       " 782: 'places',\n",
       " 783: 'peace',\n",
       " 784: 'monstrous',\n",
       " 785: 'listened',\n",
       " 786: 'immediate',\n",
       " 787: 'hung',\n",
       " 788: 'height',\n",
       " 789: 'gold',\n",
       " 790: 'fearful',\n",
       " 791: 'faces',\n",
       " 792: 'dont',\n",
       " 793: 'conversation',\n",
       " 794: 'carried',\n",
       " 795: 'arkham',\n",
       " 796: 'vague',\n",
       " 797: 'surface',\n",
       " 798: 'smile',\n",
       " 799: 'slowly',\n",
       " 800: 'situation',\n",
       " 801: 'remain',\n",
       " 802: 'reach',\n",
       " 803: 'ran',\n",
       " 804: 'queer',\n",
       " 805: 'need',\n",
       " 806: 'mouth',\n",
       " 807: 'mighty',\n",
       " 808: 'mentioned',\n",
       " 809: 'madame',\n",
       " 810: 'king',\n",
       " 811: 'hundred',\n",
       " 812: 'help',\n",
       " 813: 'extreme',\n",
       " 814: 'extent',\n",
       " 815: 'ears',\n",
       " 816: 'disease',\n",
       " 817: 'daughter',\n",
       " 818: 'corner',\n",
       " 819: 'company',\n",
       " 820: 'certainly',\n",
       " 821: 'behold',\n",
       " 822: 'balloon',\n",
       " 823: 'appear',\n",
       " 824: 'yourself',\n",
       " 825: 'village',\n",
       " 826: 'thin',\n",
       " 827: 'talk',\n",
       " 828: 'supposed',\n",
       " 829: 'shewed',\n",
       " 830: 'senses',\n",
       " 831: 'seems',\n",
       " 832: 'promise',\n",
       " 833: 'machine',\n",
       " 834: 'listen',\n",
       " 835: 'language',\n",
       " 836: 'glass',\n",
       " 837: 'features',\n",
       " 838: 'fathers',\n",
       " 839: 'familiar',\n",
       " 840: 'desire',\n",
       " 841: 'car',\n",
       " 842: 'business',\n",
       " 843: 'alas',\n",
       " 844: 'weight',\n",
       " 845: 'violent',\n",
       " 846: 'sympathy',\n",
       " 847: 'started',\n",
       " 848: 'sinister',\n",
       " 849: 'science',\n",
       " 850: 'result',\n",
       " 851: 'quiet',\n",
       " 852: 'prepared',\n",
       " 853: 'paused',\n",
       " 854: 'nose',\n",
       " 855: 'noble',\n",
       " 856: 'leaving',\n",
       " 857: 'innsmouth',\n",
       " 858: 'image',\n",
       " 859: 'glory',\n",
       " 860: 'forever',\n",
       " 861: 'determined',\n",
       " 862: 'clouds',\n",
       " 863: 'building',\n",
       " 864: 'attempt',\n",
       " 865: 'agony',\n",
       " 866: 'visited',\n",
       " 867: 'thick',\n",
       " 868: 'sufficient',\n",
       " 869: 'suffered',\n",
       " 870: 'success',\n",
       " 871: 'succeeded',\n",
       " 872: 'spring',\n",
       " 873: 'spread',\n",
       " 874: 'solitude',\n",
       " 875: 'sole',\n",
       " 876: 'reflection',\n",
       " 877: 'pocket',\n",
       " 878: 'occupied',\n",
       " 879: 'nervous',\n",
       " 880: 'hall',\n",
       " 881: 'forms',\n",
       " 882: 'follow',\n",
       " 883: 'flowers',\n",
       " 884: 'fever',\n",
       " 885: 'except',\n",
       " 886: 'dupin',\n",
       " 887: 'despite',\n",
       " 888: 'considered',\n",
       " 889: 'conduct',\n",
       " 890: 'big',\n",
       " 891: 'apparent',\n",
       " 892: 'woods',\n",
       " 893: 'waters',\n",
       " 894: 'utter',\n",
       " 895: 'trace',\n",
       " 896: 'roof',\n",
       " 897: 'relief',\n",
       " 898: 'powers',\n",
       " 899: 'ordinary',\n",
       " 900: 'notice',\n",
       " 901: 'melancholy',\n",
       " 902: 'marked',\n",
       " 903: 'm',\n",
       " 904: 'island',\n",
       " 905: 'ideas',\n",
       " 906: 'forced',\n",
       " 907: 'feared',\n",
       " 908: 'fashion',\n",
       " 909: 'expressed',\n",
       " 910: 'experienced',\n",
       " 911: 'crowd',\n",
       " 912: 'covered',\n",
       " 913: 'concerning',\n",
       " 914: 'century',\n",
       " 915: 'carefully',\n",
       " 916: 'bodies',\n",
       " 917: 'apartment',\n",
       " 918: 'aid',\n",
       " 919: 'accursed',\n",
       " 920: 'watch',\n",
       " 921: 'used',\n",
       " 922: 'unable',\n",
       " 923: 'temple',\n",
       " 924: 'tall',\n",
       " 925: 'tales',\n",
       " 926: 'study',\n",
       " 927: 'soft',\n",
       " 928: 'rock',\n",
       " 929: 'remembered',\n",
       " 930: 'recall',\n",
       " 931: 'perceive',\n",
       " 932: 'original',\n",
       " 933: 'mystery',\n",
       " 934: 'minute',\n",
       " 935: 'mental',\n",
       " 936: 'meet',\n",
       " 937: 'limbs',\n",
       " 938: 'learned',\n",
       " 939: 'lake',\n",
       " 940: 'key',\n",
       " 941: 'heavens',\n",
       " 942: 'forward',\n",
       " 943: 'enter',\n",
       " 944: 'enemy',\n",
       " 945: 'discovery',\n",
       " 946: 'destruction',\n",
       " 947: 'bitter',\n",
       " 948: 'bent',\n",
       " 949: 'anxiety',\n",
       " 950: 'answer',\n",
       " 951: 'amidst',\n",
       " 952: 'wholly',\n",
       " 953: 'week',\n",
       " 954: 'vision',\n",
       " 955: 'stranger',\n",
       " 956: 'spirits',\n",
       " 957: 'shut',\n",
       " 958: 'seem',\n",
       " 959: 'regard',\n",
       " 960: 'professor',\n",
       " 961: 'probably',\n",
       " 962: 'presented',\n",
       " 963: 'noticed',\n",
       " 964: 'material',\n",
       " 965: 'impression',\n",
       " 966: 'haunted',\n",
       " 967: 'greek',\n",
       " 968: 'greatest',\n",
       " 969: 'glance',\n",
       " 970: 'ghastly',\n",
       " 971: 'gentleman',\n",
       " 972: 'fled',\n",
       " 973: 'farewell',\n",
       " 974: 'fair',\n",
       " 975: 'dying',\n",
       " 976: 'dwelt',\n",
       " 977: 'duty',\n",
       " 978: 'departure',\n",
       " 979: 'degrees',\n",
       " 980: 'brother',\n",
       " 981: 'beside',\n",
       " 982: 'bear',\n",
       " 983: 'aside',\n",
       " 984: 'aout',\n",
       " 985: 'weak',\n",
       " 986: 'walk',\n",
       " 987: 'try',\n",
       " 988: 'sufficiently',\n",
       " 989: 'servant',\n",
       " 990: 'sent',\n",
       " 991: 'satisfied',\n",
       " 992: 'respect',\n",
       " 993: 'region',\n",
       " 994: 'produced',\n",
       " 995: 'plain',\n",
       " 996: 'permitted',\n",
       " 997: 'palace',\n",
       " 998: 'painful',\n",
       " 999: 'oclock',\n",
       " ...}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of vocab\n",
    "vocab = sequence_vectorizer.get_vocabulary()\n",
    "int_to_str = {idx: word for idx, word in enumerate(vocab)}\n",
    "int_to_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4d55351-eb1c-431e-8a8b-58ee2fce1f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'occasion'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_str[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46caf21b-c1d9-4eb1-b14a-8b1894fff8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 100), dtype=int64, numpy=\n",
       "array([[ 6345,     1,    28,    35,  6996, 13401,    18,     1,  6345,\n",
       "           57,     7,     1,    10,   833,  3862, 16160,   122,   521,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0]], dtype=int64)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the sequence of sample text with the sequence_vectorizer\n",
    "sequence= sequence_vectorizer([\"Text Vectorization is an essential tool for converting text into a format that machine learning models can use.\"])\n",
    "sequence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
